{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab53ff87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 9 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   intern_id                  1000 non-null   int64  \n",
      " 1   name                       1000 non-null   object \n",
      " 2   age                        1000 non-null   int64  \n",
      " 3   gpa                        1000 non-null   float64\n",
      " 4   skills                     1000 non-null   object \n",
      " 5   interest                   1000 non-null   object \n",
      " 6   location                   1000 non-null   object \n",
      " 7   preferred_duration_months  1000 non-null   int64  \n",
      " 8   prior_experience_years     1000 non-null   int64  \n",
      "dtypes: float64(1), int64(4), object(4)\n",
      "memory usage: 70.4+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 14 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   intern_id                  1000 non-null   int64  \n",
      " 1   name                       1000 non-null   object \n",
      " 2   age                        1000 non-null   int64  \n",
      " 3   gpa                        1000 non-null   float64\n",
      " 4   skills                     1000 non-null   object \n",
      " 5   interest                   1000 non-null   object \n",
      " 6   location                   1000 non-null   object \n",
      " 7   preferred_duration_months  1000 non-null   int64  \n",
      " 8   prior_experience_years     1000 non-null   int64  \n",
      " 9   skills_processed           1000 non-null   object \n",
      " 10  gpa_scaled                 1000 non-null   float64\n",
      " 11  age_scaled                 1000 non-null   float64\n",
      " 12  experience_scaled          1000 non-null   float64\n",
      " 13  duration_scaled            1000 non-null   float64\n",
      "dtypes: float64(5), int64(4), object(5)\n",
      "memory usage: 109.5+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------\n",
    "# Utility / pipeline functions (simplified)\n",
    "# -----------------------\n",
    "\n",
    "def safe_read_csv(path):\n",
    "    try:\n",
    "        return pd.read_csv(path)\n",
    "    except Exception as e:\n",
    "        messagebox.showerror('File error', f'Could not read CSV:\\n{e}')\n",
    "        return None\n",
    "\n",
    "\n",
    "def preprocess_data(interns_df, companies_df):\n",
    "    interns = interns_df.copy()\n",
    "    companies = companies_df.copy()\n",
    "\n",
    "    interns.fillna({'skills': '', 'interest': '', 'location': 'Unknown'}, inplace=True)\n",
    "    companies.fillna({'requirements': '', 'domain': '', 'location': 'Unknown', 'stipend': 0}, inplace=True)\n",
    "\n",
    "    def preprocess_text(text):\n",
    "        if pd.isna(text):\n",
    "            return ''\n",
    "        return str(text).lower().strip().replace(',', ' ').replace('/', ' ')\n",
    "\n",
    "    interns['skills_processed'] = interns['skills'].apply(preprocess_text)\n",
    "    companies['requirements_processed'] = companies['requirements'].apply(preprocess_text)\n",
    "    interns['interest'] = interns['interest'].astype(str).str.lower()\n",
    "    companies['domain'] = companies['domain'].astype(str).str.lower()\n",
    "\n",
    "    # TF-IDF vectorization\n",
    "    tfidf = TfidfVectorizer(max_features=100, stop_words='english')\n",
    "    all_text = pd.concat([interns['skills_processed'], companies['requirements_processed']])\n",
    "    tfidf.fit(all_text)\n",
    "    intern_skills_tfidf = tfidf.transform(interns['skills_processed'])\n",
    "    company_req_tfidf = tfidf.transform(companies['requirements_processed'])\n",
    "\n",
    "    # scaling (fit separately for stability)\n",
    "    s_gpa = StandardScaler()\n",
    "    s_stipend = StandardScaler()\n",
    "    s_min_gpa = StandardScaler()\n",
    "    s_age = StandardScaler()\n",
    "    s_exp = StandardScaler()\n",
    "    s_dur = StandardScaler()\n",
    "\n",
    "    interns['gpa_scaled'] = s_gpa.fit_transform(interns[['gpa']]) if 'gpa' in interns.columns else 0\n",
    "    companies['stipend_scaled'] = s_stipend.fit_transform(companies[['stipend']]) if 'stipend' in companies.columns else 0\n",
    "    companies['min_gpa_scaled'] = s_min_gpa.fit_transform(companies[['min_gpa']]) if 'min_gpa' in companies.columns else 0\n",
    "    interns['age_scaled'] = s_age.fit_transform(interns[['age']]) if 'age' in interns.columns else 0\n",
    "    interns['experience_scaled'] = s_exp.fit_transform(interns[['prior_experience_years']]) if 'prior_experience_years' in interns.columns else 0\n",
    "    interns['duration_scaled'] = s_dur.fit_transform(interns[['preferred_duration_months']]) if 'preferred_duration_months' in interns.columns else 0\n",
    "\n",
    "    return interns, companies, intern_skills_tfidf, company_req_tfidf\n",
    "\n",
    "\n",
    "def create_feature_matrix(interns, companies, intern_skills_tfidf, company_req_tfidf):\n",
    "    features = []\n",
    "    for i in range(len(interns)):\n",
    "        for j in range(len(companies)):\n",
    "            skills_sim = cosine_similarity(intern_skills_tfidf[i:i+1], company_req_tfidf[j:j+1])[0][0]\n",
    "            gpa_score = 0\n",
    "            try:\n",
    "                if interns.iloc[i]['gpa'] >= companies.iloc[j]['min_gpa']:\n",
    "                    gpa_score = min((interns.iloc[i]['gpa'] - companies.iloc[j]['min_gpa']) / (10.0 - companies.iloc[j]['min_gpa']), 1.0)\n",
    "            except Exception:\n",
    "                gpa_score = 0\n",
    "\n",
    "            interest_score = 1.0 if interns.iloc[i]['interest'] == companies.iloc[j]['domain'] else \\\n",
    "                             0.5 if (interns.iloc[i]['interest'] in companies.iloc[j]['domain'] or \\\n",
    "                                     companies.iloc[j]['domain'] in interns.iloc[i]['interest']) else 0.0\n",
    "            location_score = 1.0 if interns.iloc[i]['location'] == companies.iloc[j]['location'] else 0.0\n",
    "            age_score = min(interns.iloc[i]['age_scaled'] / 25, 1.0) if 'age_scaled' in interns.columns else 0\n",
    "            experience_score = interns.iloc[i]['experience_scaled'] if 'experience_scaled' in interns.columns else 0\n",
    "            duration_score = interns.iloc[i]['duration_scaled'] if 'duration_scaled' in interns.columns else 0\n",
    "\n",
    "            features.append({\n",
    "                'intern_idx': i,\n",
    "                'company_idx': j,\n",
    "                'skills_similarity': skills_sim,\n",
    "                'gpa_score': gpa_score,\n",
    "                'interest_score': interest_score,\n",
    "                'location_score': location_score,\n",
    "                'age_score': age_score,\n",
    "                'experience_score': experience_score,\n",
    "                'duration_score': duration_score\n",
    "            })\n",
    "    fm = pd.DataFrame(features)\n",
    "    X = fm[['skills_similarity', 'gpa_score', 'interest_score', 'location_score', 'age_score', 'experience_score', 'duration_score']]\n",
    "    return fm, X\n",
    "\n",
    "\n",
    "def synthesize_target(X):\n",
    "    # add small noise and construct a synthetic target to train on (same idea as original script)\n",
    "    np.random.seed(42)\n",
    "    noise = np.random.normal(0, 5, len(X))\n",
    "    y = (X['skills_similarity'] * 40 + X['gpa_score'] * 20 + X['interest_score'] * 15 + \n",
    "         X['location_score'] * 10 + X['age_score'] * 5 + X['experience_score'] * 5 + \n",
    "         X['duration_score'] * 5 + noise)\n",
    "    return y\n",
    "\n",
    "\n",
    "def train_and_select_model(X, y):\n",
    "    models = {\n",
    "        'Ridge Regression': Ridge(alpha=1.0),\n",
    "        'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=4, random_state=42),\n",
    "        'Support Vector Regressor': SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "    }\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    results = []\n",
    "    for name, model in models.items():\n",
    "        rmses, maes, r2s = [], [], []\n",
    "        for train_idx, test_idx in cv.split(X_scaled):\n",
    "            model.fit(X_scaled.iloc[train_idx], y.iloc[train_idx])\n",
    "            y_pred = model.predict(X_scaled.iloc[test_idx])\n",
    "            rmses.append(np.sqrt(mean_squared_error(y.iloc[test_idx], y_pred)))\n",
    "            maes.append(mean_absolute_error(y.iloc[test_idx], y_pred))\n",
    "            r2s.append(r2_score(y.iloc[test_idx], y_pred))\n",
    "        model.fit(X_scaled, y)  # fit final\n",
    "        results.append({'name': name, 'model': model, 'rmse': np.mean(rmses), 'mae': np.mean(maes), 'r2': np.mean(r2s)})\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    best_idx = results_df['rmse'].idxmin()\n",
    "    best = results[best_idx]\n",
    "    return best, results_df\n",
    "\n",
    "\n",
    "def allocate_internships(predicted_scores, interns, companies, weight_match=0.7, weight_stipend=0.3):\n",
    "    allocations = []\n",
    "    allocated_interns = set()\n",
    "    company_slots = companies['slots'].tolist() if 'slots' in companies.columns else [1]*len(companies)\n",
    "    combined_scores = (weight_match * predicted_scores + weight_stipend * (companies['stipend'].values / (companies['stipend'].max() if companies['stipend'].max()>0 else 1)))\n",
    "\n",
    "    all_matches = [(combined_scores[i, j], i, j) for i in range(predicted_scores.shape[0]) for j in range(predicted_scores.shape[1])]\n",
    "    all_matches.sort(reverse=True, key=lambda x: x[0])\n",
    "\n",
    "    for score, intern_idx, company_idx in all_matches:\n",
    "        if intern_idx not in allocated_interns and company_slots[company_idx] > 0:\n",
    "            allocations.append({\n",
    "                'intern_id': interns.iloc[intern_idx].get('intern_id', intern_idx),\n",
    "                'name': interns.iloc[intern_idx].get('name', f'Intern {intern_idx}'),\n",
    "                'company_name': companies.iloc[company_idx].get('company_name', f'Company {company_idx}'),\n",
    "                'match_score': float(predicted_scores[intern_idx, company_idx]),\n",
    "                'stipend': float(companies.iloc[company_idx].get('stipend', 0)),\n",
    "                'combined_score': float(score)\n",
    "            })\n",
    "            allocated_interns.add(intern_idx)\n",
    "            company_slots[company_idx] -= 1\n",
    "\n",
    "    return pd.DataFrame(allocations)\n",
    "\n",
    "# -----------------------\n",
    "# GUI\n",
    "# -----------------------\n",
    "\n",
    "class InternshipApp(tk.Tk):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.title('Internship Allocation - Simple UI')\n",
    "        self.geometry('1100x700')\n",
    "\n",
    "        # Data holders\n",
    "        self.interns_df = None\n",
    "        self.companies_df = None\n",
    "        self.intern_skills_tfidf = None\n",
    "        self.company_req_tfidf = None\n",
    "        self.feature_matrix = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.best_model = None\n",
    "        self.results_df = None\n",
    "        self.allocations = None\n",
    "\n",
    "        # Layout\n",
    "        self.create_widgets()\n",
    "\n",
    "    def create_widgets(self):\n",
    "        # Left control frame\n",
    "        control = ttk.Frame(self)\n",
    "        control.pack(side='left', fill='y', padx=8, pady=8)\n",
    "\n",
    "        ttk.Button(control, text='Load Interns CSV', command=self.load_interns).pack(fill='x', pady=4)\n",
    "        ttk.Button(control, text='Load Companies CSV', command=self.load_companies).pack(fill='x', pady=4)\n",
    "        ttk.Separator(control).pack(fill='x', pady=6)\n",
    "        ttk.Button(control, text='Run EDA', command=self.run_eda).pack(fill='x', pady=4)\n",
    "        ttk.Button(control, text='Show Plots', command=self.show_plots).pack(fill='x', pady=4)\n",
    "        ttk.Separator(control).pack(fill='x', pady=6)\n",
    "        ttk.Button(control, text='Preprocess & Build Features', command=self.build_features).pack(fill='x', pady=4)\n",
    "        ttk.Button(control, text='Train Models & Select Best', command=self.train_models).pack(fill='x', pady=4)\n",
    "        ttk.Button(control, text='Run Allocation', command=self.run_allocation).pack(fill='x', pady=4)\n",
    "        ttk.Separator(control).pack(fill='x', pady=6)\n",
    "        ttk.Button(control, text='Export Allocations', command=self.export_allocations).pack(fill='x', pady=4)\n",
    "\n",
    "        self.status_var = tk.StringVar(value='Status: waiting for input')\n",
    "        ttk.Label(control, textvariable=self.status_var, wraplength=200).pack(fill='x', pady=10)\n",
    "\n",
    "        # Right notebook for outputs\n",
    "        self.nb = ttk.Notebook(self)\n",
    "        self.nb.pack(side='right', expand=True, fill='both')\n",
    "\n",
    "        # EDA tab\n",
    "        self.eda_frame = ttk.Frame(self.nb)\n",
    "        self.nb.add(self.eda_frame, text='EDA / Summary')\n",
    "        self.eda_text = tk.Text(self.eda_frame)\n",
    "        self.eda_text.pack(expand=True, fill='both')\n",
    "\n",
    "        # Plot tab\n",
    "        self.plot_frame = ttk.Frame(self.nb)\n",
    "        self.nb.add(self.plot_frame, text='Plots')\n",
    "\n",
    "        # Allocations tab\n",
    "        self.alloc_frame = ttk.Frame(self.nb)\n",
    "        self.nb.add(self.alloc_frame, text='Allocations')\n",
    "        self.tree = ttk.Treeview(self.alloc_frame, columns=('intern_id','name','company','match','stipend','combined'), show='headings')\n",
    "        for c in self.tree['columns']:\n",
    "            self.tree.heading(c, text=c)\n",
    "        self.tree.pack(expand=True, fill='both')\n",
    "\n",
    "    # ----------------------- GUI callbacks\n",
    "    def load_interns(self):\n",
    "        path = filedialog.askopenfilename(title='Select interns CSV', filetypes=[('CSV files','*.csv'),('All files','*.*')])\n",
    "        if not path:\n",
    "            return\n",
    "        df = safe_read_csv(path)\n",
    "        if df is not None:\n",
    "            self.interns_df = df\n",
    "            self.status_var.set(f'Loaded interns: {len(df)} rows')\n",
    "\n",
    "    def load_companies(self):\n",
    "        path = filedialog.askopenfilename(title='Select companies CSV', filetypes=[('CSV files','*.csv'),('All files','*.*')])\n",
    "        if not path:\n",
    "            return\n",
    "        df = safe_read_csv(path)\n",
    "        if df is not None:\n",
    "            self.companies_df = df\n",
    "            self.status_var.set(f'Loaded companies: {len(df)} rows')\n",
    "\n",
    "    def run_eda(self):\n",
    "        if self.interns_df is None or self.companies_df is None:\n",
    "            messagebox.showwarning('Missing data', 'Please load both interns and companies CSVs first.')\n",
    "            return\n",
    "        interns = self.interns_df\n",
    "        companies = self.companies_df\n",
    "        self.eda_text.delete('1.0', 'end')\n",
    "        self.eda_text.insert('end', '--- Interns Info ---\\n')\n",
    "        self.eda_text.insert('end', f'{interns.info() if hasattr(interns, \"info\") else \"No info\"}\\n')\n",
    "        self.eda_text.insert('end', '\\nDescriptive stats for interns:\\n')\n",
    "        self.eda_text.insert('end', interns.describe(include='all').to_string())\n",
    "        self.eda_text.insert('end', '\\n\\n--- Companies Info ---\\n')\n",
    "        self.eda_text.insert('end', companies.describe(include='all').to_string())\n",
    "        # quick insights\n",
    "        try:\n",
    "            avg_gpa = interns['gpa'].mean()\n",
    "            common_interest = interns['interest'].mode()[0]\n",
    "            common_skill = interns['skills'].str.split(', ').explode().mode()[0]\n",
    "            total_slots = companies['slots'].sum()\n",
    "            avg_stipend = companies['stipend'].mean()\n",
    "            common_domain = companies['domain'].mode()[0]\n",
    "            insights = f\"\\n\\nBusiness Insights:\\n- Average GPA: {avg_gpa:.2f}\\n- Most common interest: {common_interest}\\n- Most common skill: {common_skill}\\n- Total slots: {int(total_slots)}\\n- Average stipend: {avg_stipend:.2f}\\n- Most common domain: {common_domain}\\n\"\n",
    "            self.eda_text.insert('end', insights)\n",
    "        except Exception:\n",
    "            pass\n",
    "        self.status_var.set('EDA complete.')\n",
    "\n",
    "    def show_plots(self):\n",
    "        if self.interns_df is None or self.companies_df is None:\n",
    "            messagebox.showwarning('Missing data', 'Please load both interns and companies CSVs first.')\n",
    "            return\n",
    "        for w in self.plot_frame.winfo_children():\n",
    "            w.destroy()\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(8,6))\n",
    "        interns = self.interns_df\n",
    "        companies = self.companies_df\n",
    "        try:\n",
    "            axes[0,0].hist(interns['gpa'].dropna(), bins=10)\n",
    "            axes[0,0].set_title('GPA Distribution')\n",
    "        except Exception:\n",
    "            axes[0,0].text(0.5, 0.5, 'No GPA data', ha='center')\n",
    "        try:\n",
    "            interns['interest'].value_counts().nlargest(6).plot(kind='bar', ax=axes[0,1])\n",
    "            axes[0,1].set_title('Top Interests')\n",
    "        except Exception:\n",
    "            axes[0,1].text(0.5, 0.5, 'No interest data', ha='center')\n",
    "        try:\n",
    "            companies['domain'].value_counts().nlargest(6).plot(kind='bar', ax=axes[1,0])\n",
    "            axes[1,0].set_title('Top Company Domains')\n",
    "        except Exception:\n",
    "            axes[1,0].text(0.5, 0.5, 'No domain data', ha='center')\n",
    "        try:\n",
    "            axes[1,1].scatter(interns['gpa'], interns['prior_experience_years'])\n",
    "            axes[1,1].set_title('GPA vs Experience')\n",
    "        except Exception:\n",
    "            axes[1,1].text(0.5, 0.5, 'No data', ha='center')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        canvas = FigureCanvasTkAgg(fig, master=self.plot_frame)\n",
    "        canvas.get_tk_widget().pack(expand=True, fill='both')\n",
    "        canvas.draw()\n",
    "        self.status_var.set('Plots displayed.')\n",
    "\n",
    "    def build_features(self):\n",
    "        if self.interns_df is None or self.companies_df is None:\n",
    "            messagebox.showwarning('Missing data', 'Please load both interns and companies CSVs first.')\n",
    "            return\n",
    "        self.interns_df, self.companies_df, self.intern_skills_tfidf, self.company_req_tfidf = preprocess_data(self.interns_df, self.companies_df)\n",
    "        fm, X = create_feature_matrix(self.interns_df, self.companies_df, self.intern_skills_tfidf, self.company_req_tfidf)\n",
    "        self.feature_matrix = fm\n",
    "        self.X = X\n",
    "        self.status_var.set(f'Feature matrix built: {len(X)} rows')\n",
    "\n",
    "    def train_models(self):\n",
    "        if self.X is None:\n",
    "            messagebox.showwarning('Missing features', 'Please run Preprocess & Build Features first.')\n",
    "            return\n",
    "        self.y = synthesize_target(self.X)\n",
    "        best, results_df = train_and_select_model(self.X, self.y)\n",
    "        self.best_model = best['model']\n",
    "        self.results_df = results_df\n",
    "        self.status_var.set(f\"Trained models. Best: {best['name']} (RMSE {best['rmse']:.3f})\")\n",
    "        # show results in EDA tab\n",
    "        self.eda_text.insert('end', '\\n\\nModel cross-validation results:\\n')\n",
    "        self.eda_text.insert('end', results_df.to_string())\n",
    "\n",
    "    def run_allocation(self):\n",
    "        if self.best_model is None or self.feature_matrix is None:\n",
    "            messagebox.showwarning('Missing step', 'Please build features and train models first.')\n",
    "            return\n",
    "        n_interns = len(self.interns_df)\n",
    "        n_companies = len(self.companies_df)\n",
    "        # reconstruct matrices similarly to training\n",
    "        skills_sim_matrix = cosine_similarity(self.intern_skills_tfidf, self.company_req_tfidf)\n",
    "        gpa_matrix = np.maximum(0, (self.interns_df['gpa'].values[:, None] - self.companies_df['min_gpa'].values[None, :]) / (10 - self.companies_df['min_gpa'].values[None, :]))\n",
    "        interest_matrix = np.array([[1 if self.interns_df.iloc[i]['interest']==self.companies_df.iloc[j]['domain']\n",
    "                                     else 0.5 if self.interns_df.iloc[i]['interest'] in self.companies_df.iloc[j]['domain']\n",
    "                                     else 0\n",
    "                                     for j in range(n_companies)]\n",
    "                                    for i in range(n_interns)])\n",
    "        location_matrix = (self.interns_df['location'].values[:, None] == self.companies_df['location'].values[None, :]).astype(float)\n",
    "\n",
    "        age_matrix = np.repeat(self.interns_df['age_scaled'].values[:, None], n_companies, axis=1) / 25\n",
    "        experience_matrix = np.repeat(self.interns_df['experience_scaled'].values[:, None], n_companies, axis=1)\n",
    "        duration_matrix = np.repeat(self.interns_df['duration_scaled'].values[:, None], n_companies, axis=1)\n",
    "\n",
    "        X_vectorized = np.stack([skills_sim_matrix, gpa_matrix, interest_matrix, location_matrix, age_matrix, experience_matrix, duration_matrix], axis=2).reshape(-1,7)\n",
    "        scaler = StandardScaler()\n",
    "        # note: best_model was fit to scaled X during training; use same scaling approach\n",
    "        X_scaled = scaler.fit_transform(self.X)\n",
    "        # to get predictions, we also scale X_vectorized with same scaler fitted on X\n",
    "        Xv_scaled = scaler.transform(X_vectorized)\n",
    "        preds = self.best_model.predict(Xv_scaled).reshape(n_interns, n_companies)\n",
    "\n",
    "        allocations_df = allocate_internships(preds, self.interns_df, self.companies_df)\n",
    "        self.allocations = allocations_df\n",
    "\n",
    "        # populate treeview\n",
    "        for i in self.tree.get_children():\n",
    "            self.tree.delete(i)\n",
    "        if not allocations_df.empty:\n",
    "            for _, row in allocations_df.iterrows():\n",
    "                self.tree.insert('', 'end', values=(row['intern_id'], row['name'], row['company_name'], f\"{row['match_score']:.3f}\", int(row['stipend']), f\"{row['combined_score']:.3f}\"))\n",
    "            self.status_var.set(f'Allocation complete: {len(allocations_df)} interns allocated')\n",
    "        else:\n",
    "            messagebox.showinfo('No allocations', 'No allocations produced.')\n",
    "            self.status_var.set('Allocation produced 0 results')\n",
    "\n",
    "    def export_allocations(self):\n",
    "        if self.allocations is None or self.allocations.empty:\n",
    "            messagebox.showwarning('No data', 'No allocations to export. Run allocation first.')\n",
    "            return\n",
    "        path = filedialog.asksaveasfilename(defaultextension='.csv', filetypes=[('CSV files','*.csv')])\n",
    "        if not path:\n",
    "            return\n",
    "        self.allocations.to_csv(path, index=False)\n",
    "        messagebox.showinfo('Exported', f'Allocations exported to {path}')\n",
    "\n",
    "# -----------------------\n",
    "# Run app\n",
    "# -----------------------\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app = InternshipApp()\n",
    "    app.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_env_pyorg)",
   "language": "python",
   "name": "ml_env_pyorg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
